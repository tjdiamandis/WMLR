"""
Computes ğ–¤[Ïˆ_{Î², Î³áµ¢}(x, y)]
"""
function E_psi(Î²::AbstractVector{T}, Î³â‚::AbstractVector{T}, Î³â‚‚::AbstractVector{T}, data, p) where {T}
    arg1, arg2, ret = zero(T), zero(T), zero(T)
    @inbounds for ii in 1:length(data.y)
        x_i = @view(data.x[ii,:])
        y_i = data.y[ii]
        arg1 = y_i * dot(Î³â‚, x_i)
        arg2 = y_i * dot(Î³â‚‚, x_i)
        # function Ïˆ, as defined in paper
        ret += (logaddexp(-arg1, arg1) - logaddexp(-arg2, arg2))
    end
    return ret / length(data.y)
end


"""
Non-allocating f(Î², Î³áµ¢, data)
"""
function f(Î²::AbstractVector{T}, Î³â‚::AbstractVector{T}, Î³â‚‚::AbstractVector{T}, data, p, cache) where {T}
    x_gen = data.x

    # Compute regularization (unallocating)
    reg = zero(T)
    @inbounds for ii in 1:p.d
        reg += (Î³â‚[ii] - p.Î³Ìƒ[ii]).^2
        reg += (Î³â‚‚[ii] - p.Î³Ìƒ[ii]).^2
    end
    reg *= p.Î»/2

    # Calculate y_generator (unallocating)
    rand!(cache.rand_k, (-1,1))
    randn!(cache.rand_noise)

    mul!(cache.y_gen, x_gen, Î²)
    cache.y_gen .= cache.rand_k .* cache.y_gen .+ cache.rand_noise
    return E_psi(Î², Î³â‚, Î³â‚‚, data, p) - E_psi(Î², Î³â‚, Î³â‚‚, (x=x_gen, y=cache.y_gen), p) - reg
end


"""
Allocating version of f(Î², Î³áµ¢, data) for reverse mode AD
"""
function f(Î²::AbstractVector{T}, Î³â‚::AbstractVector{T}, Î³â‚‚::AbstractVector{T}, data, p) where {T}
    x_gen = data.x

    # Compute regularization
    reg = zero(T)
    @inbounds for ii in 1:p.d
        reg += (Î³â‚[ii] - p.Î³Ìƒ[ii]).^2
        reg += (Î³â‚‚[ii] - p.Î³Ìƒ[ii]).^2
    end
    reg *= p.Î»/2

    y_gen = rand((-1,1), p.N) .* x_gen*Î² .+ randn(p.N)
    return E_psi(Î², Î³â‚, Î³â‚‚, data, p) - E_psi(Î², Î³â‚, Î³â‚‚, (x=x_gen, y=y_gen), p) - reg
    # return E_psi(Î², Î³â‚, Î³â‚‚, data, p) - E_psi(Î², Î³â‚, Î³â‚‚, (x=x_gen, y=y_gen), p) - p.Î»/2 * (sum(abs2, Î³â‚ - p.Î³Ìƒ) + sum(abs2, Î³â‚ - p.Î³Ìƒ))
end


"""
Get compiled gradient of f wrt vars (Î², Î³â‚, Î³â‚‚)
"""
function get_grad_function_rd(data, p)
    results = (
        Vector{Float64}(undef, p.d),
        Vector{Float64}(undef, p.d),
        Vector{Float64}(undef, p.d),
    )
    f_tape = GradientTape((Î², Î³â‚, Î³â‚‚) -> f(Î², Î³â‚, Î³â‚‚, data, p), results)
    compiled_f_tape = compile(f_tape)

    âˆ‡f!(results, inputs) = gradient!(results, compiled_f_tape, inputs)
    return âˆ‡f!
end


"""
Take GDA step for variables vars using âˆ‡f! and stores in results
"""
function _gda_step(âˆ‡f!, vars, results, p)
    # Compute gradient
    âˆ‡f!(results, vars)

    # Update variables
    @. vars[1] = vars[1] - p.Î±_min*results[1]
    @. vars[2] = vars[2] + p.Î±_max*results[2]
    @. vars[3] = vars[3] + p.Î±_max*results[3]
end
